{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "## need biopython to run: https://anaconda.org/anaconda/biopython\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "from Bio.Seq import Seq\n",
    "## need OligoArrayAux to run: http://www.unafold.org/Dinamelt/software/OligoArrayAux.php\n",
    "import oligo_melting as OligoMelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurization\n",
    "### Functions\n",
    "can definitely be improved upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_at_position(string, letter, position):\n",
    "    ## takes in a string, letter (both as strings), and position as an integer\n",
    "    ## returns boolean whether the given letter is at the given position in the string\n",
    "    return string[position:position+1].__eq__(letter)\n",
    "\n",
    "def tuple_at_position(string, letters, position):\n",
    "    ## takes in a string, 2 letters (as a single string) and position as an integer\n",
    "    ## returns boolean whether the given letters are at the given position in the string\n",
    "    return string[position:position+2].__eq__(letters)\n",
    "\n",
    "def triple_at_position(string, letters, position):\n",
    "    ## takes in a string, 3 letters (as a single string) and position as an integer\n",
    "    ## returns boolean whether the given letters are at the given position in the string\n",
    "    return string[position:position+3].__eq__(letters)\n",
    "\n",
    "def find_PAM(sequence, PAM):\n",
    "    ## takes in sequence and PAM as strings representing genetic target sequence and the promotospacer-adjacent motif\n",
    "    ## of the gene editing complex\n",
    "    ## returns the position as an int or -1 if not found\n",
    "    match = re.search(PAM, sequence)\n",
    "    return match.start()\n",
    "\n",
    "def gc_count(string):\n",
    "    ## takes in a string\n",
    "    ## returns an integer representing the number of G or C letters in that string\n",
    "    count = 0\n",
    "    for letter in string:\n",
    "        if letter.__eq__('G') | letter.__eq__('C'):\n",
    "            count=count+1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doench et al 2014 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doench=pd.ExcelFile(\"Doench 2014 Supplemental Tables.xlsx\")\n",
    "print(df_doench.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_features=pd.read_excel(\"Doench 2014 Supplemental Tables.xlsx\", sheet_name=\"Supp Table 8\")\n",
    "df_table_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_data=pd.read_excel(\"Doench 2014 Supplemental Tables.xlsx\", sheet_name=\"Supp Table 10\")\n",
    "df_table_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to find more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolating necessary data into one dataframe\n",
    "- combine only necessary columns into one succinct dataframe\n",
    "    - include anything that could be useful to models\n",
    "- plot some graphs to visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to do\n",
    "df_features=df_table_sgRNA_scores[[\"Sequence\",\"Expanded Sequence\",\"sgRNA Score\"]]\n",
    "df_features[\"sgRNA Rank\"] = df_features[\"sgRNA Score\"].rank(method='max')\n",
    "n = df_features[\"sgRNA Rank\"].size\n",
    "# D=(r âˆ’ 3/8) / (n + 1/4)\n",
    "df_features[\"sgRNA Normalized\"] = (df_features[\"sgRNA Rank\"] - (3/8)) / (n + 1/4)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_V2[\"sgRNA Normalized\"], alpha=0.5, density=True, label='Normalized sgRNA scores')\n",
    "plt.hist(df_V2[\"sgRNA Score\"], alpha=0.5, density=True, label='Raw sgRNA scores')\n",
    "plt.ylabel('Probability density')\n",
    "plt.title(\"V2 Dataset Histogram sgRNA scores\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1 Featurization\n",
    "can definitely be improved upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_V1 = df_features.copy(deep=True) ## creates a hard copy of supplementary table 7 data to work with\n",
    "df_V1['Sequence'] = df_V1['Sequence'].astype('string') ## sets data of sequence to String for parsing\n",
    "df_V1['Expanded Sequence'] = df_V1['Expanded Sequence'].astype('string') ## sets data of sequence to String for parsing\n",
    "df_V1['Expanded Sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1_bool_parameters=[\"GC<10\",\"GC>10\"]\n",
    "\n",
    "for k in range(30):\n",
    "    ## creates columns for each nucleotide at each position in sequence\n",
    "    for x in ['A',\"G\",\"C\",\"T\"]:\n",
    "        df_V1[x + str(k+1)] = letter_at_position(df_V1['Sequence'],x,k)\n",
    "        V1_bool_parameters.append(x + str(k+1))\n",
    "        if k < 29:\n",
    "            for y in [\"A\",\"G\",\"C\",\"T\"]:\n",
    "                df_V1[x + y + str(k+1)] = tuple_at_position(df_V1['Sequence'],x+y,k)\n",
    "                V1_bool_parameters.append(x + y + str(k+1))\n",
    "        else:\n",
    "            for y in [\"A\",\"G\",\"C\",\"T\"]:\n",
    "                df_V1[x + y + \"?\"] =  False # not technically correct but will work as placeholder\n",
    "                df_V1[x + y + \"_PAM\"] = False # this as well\n",
    "                V1_bool_parameters.append(x + y + \"?\")\n",
    "                V1_bool_parameters.append(x + y + \"_PAM\")\n",
    "        df_V1[x + \"?\"] = False # same with this\n",
    "        V1_bool_parameters.append(x + \"?\")\n",
    "        \n",
    "df_V1['GC Count'] = -1 ## creates column for GC count\n",
    "df_V1[\"PAM position (expanded sequence)\"] = -1\n",
    "\n",
    "df_V1['Melting Temp Wallace'] = 0\n",
    "df_V1['Melting Temp GC'] = 0\n",
    "df_V1['Melting Temp NN1'] = 0\n",
    "df_V1['Melting Temp NN2'] = 0\n",
    "df_V1['Melting Temp NN3'] = 0\n",
    "df_V1['Melting Temp NN4'] = 0\n",
    "\n",
    "df_V1[\"GC<10\"] = False\n",
    "df_V1[\"GC>10\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(df_V1['Sequence'].size):\n",
    "    ## loops through each sequence and computes the necessary one-hot nucleotide encoding features\n",
    "    for k in range(30):\n",
    "        for x in ['A',\"G\",\"C\",\"T\"]:\n",
    "            df_V1[x + str(k+1)][a] = letter_at_position(df_V1['Sequence'][a],x,k)\n",
    "            if k < 29:\n",
    "                for y in [\"A\",\"G\",\"C\",\"T\"]:\n",
    "                    df_V1[x + y + str(k+1)][a] = tuple_at_position(df_V1['Sequence'][a],x+y,k)\n",
    "                    if (not df_V1[x + y + \"?\"][a]):\n",
    "                        df_V1[x + y + \"?\"][a] = df_V1[x + y + str(k+1)][a]\n",
    "            \n",
    "            if (not df_V1[x + \"?\"][a]):\n",
    "                df_V1[x + \"?\"][a] = df_V1[x + str(k+1)][a]\n",
    "                        \n",
    "    ## generates the GC count data for each column\n",
    "    df_V1['GC Count'][a] = gc_count(df_V1['Sequence'][a])\n",
    "    ## calculates the PAM position for each sequence\n",
    "    df_V1[\"PAM position (expanded sequence)\"][a] = find_PAM(df_V1[\"Expanded Sequence\"][a],\"GG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(df_V1['Expanded Sequence'].size):\n",
    "    df_V1[\"PAM position (expanded sequence)\"][a] = find_PAM(df_V1[\"Expanded Sequence\"][a],\"GG\")\n",
    "    for x in ['A',\"G\",\"C\",\"T\"]:\n",
    "        for y in ['A',\"G\",\"C\",\"T\"]:\n",
    "            df_V1[x + y + \"_PAM\"] = tuple_at_position(df_V1[\"Expanded Sequence\"][a],\n",
    "                                                      x+y,\n",
    "                                                      df_V1[\"PAM position (expanded sequence)\"][a]-3)\n",
    "    seq = Seq(df_V1[\"Expanded Sequence\"][a])\n",
    "    df_V1[\"Melting Temp Wallace\"][a] = mt.Tm_Wallace(seq)\n",
    "    df_V1[\"Melting Temp GC\"][a] = mt.Tm_GC(seq)\n",
    "    df_V1[\"Melting Temp NN1\"][a] = mt.Tm_NN(seq, nn_table=mt.DNA_NN1)\n",
    "    df_V1[\"Melting Temp NN2\"][a] = mt.Tm_NN(seq, nn_table=mt.DNA_NN2)\n",
    "    df_V1[\"Melting Temp NN3\"][a] = mt.Tm_NN(seq, nn_table=mt.DNA_NN3)\n",
    "    df_V1[\"Melting Temp NN4\"][a] = mt.Tm_NN(seq, nn_table=mt.DNA_NN4)\n",
    "    \n",
    "    df_V1[\"GC<10\"][a] = df_V1[\"GC Count\"][a] < 10\n",
    "    df_V1[\"GC>10\"][a] = df_V1[\"GC Count\"][a] > 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v1 in V1_bool_parameters:\n",
    "    df_V1[v1]=df_V1[v1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_V1.to_csv('Doench2014_V1_Featurized.csv')\n",
    "df_V1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V2 Featurization\n",
    "can definitely be improved upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_V2 = df_V1.copy(deep=True)\n",
    "V2_bool_parameters=V1_bool_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_V2[\"AAAAA\"] = \"AAAAA\" in df_V2[\"Expanded Sequence\"] ## initializes each column to false\n",
    "df_V2[\"GGGGG\"] = \"GGGGG\" in df_V2[\"Expanded Sequence\"]\n",
    "df_V2[\"CCCCC\"] = \"CCCCC\" in df_V2[\"Expanded Sequence\"]\n",
    "df_V2[\"TTTTT\"] = \"TTTTT\" in df_V2[\"Expanded Sequence\"]\n",
    "V2_bool_parameters.append([\"AAAAA\",\"GGGGG\",\"CCCCC\",\"TTTTT\"])\n",
    "df_V2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(29):\n",
    "    for x in ['A',\"G\",\"C\",\"T\"]:\n",
    "        for y in ['A',\"G\",\"C\",\"T\"]:\n",
    "            for z in [\"A\",\"G\",\"C\",\"T\"]:\n",
    "                \n",
    "                if k < 28:\n",
    "                    df_V2[x + y + z + str(k+1)] = False\n",
    "                    V2_bool_parameters.append(x + y + z + str(k+1))\n",
    "                else:\n",
    "                    df_V2[x+y+z] = False\n",
    "                    V2_bool_parameters.append(x+y+z)\n",
    "df_V2[\"Delta G\"] = 0\n",
    "df_V2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(df_V2['Expanded Sequence'].size):\n",
    "    df_V2[\"AAAAA\"][a] = \"AAAAA\" in df_V2[\"Expanded Sequence\"][a]\n",
    "    df_V2[\"GGGGG\"][a] = \"GGGGG\" in df_V2[\"Expanded Sequence\"][a]\n",
    "    df_V2[\"CCCCC\"][a] = \"CCCCC\" in df_V2[\"Expanded Sequence\"][a]\n",
    "    df_V2[\"TTTTT\"][a] = \"TTTTT\" in df_V2[\"Expanded Sequence\"][a]\n",
    "    \n",
    "    for k in range(29):\n",
    "        for x in ['A',\"G\",\"C\",\"T\"]:\n",
    "            for y in ['A',\"G\",\"C\",\"T\"]:\n",
    "                for z in [\"A\",\"G\",\"C\",\"T\"]:\n",
    "\n",
    "                    if k < 28:\n",
    "                        df_V2[x + y + z + str(k+1)][a] = triple_at_position(df_V2[\"Expanded Sequence\"][a], x+y+z, k)\n",
    "                        if (not df_V2[x+y+z][a]):\n",
    "                            df_V2[x+y+z][a] = df_V2[x + y + z + str(k+1)][a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(df_V2['Sequence'].size):\n",
    "    ## note that this uses the 20-n.t. guide RNA sequence\n",
    "    ## all previously calculated features use the 30-oligo target sequence\n",
    "    \n",
    "    # # Calculate melting temperature for 25uM oligos\n",
    "    # (name, g, h, s, tm, seq)\n",
    "    df_V2[\"Delta G\"][a] = OligoMelt.Duplex.calc_tm(df_V2[\"Sequence\"][a])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v2 in V2_bool_parameters:\n",
    "    df_V2[v2]=df_V2[v2].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_V2.to_csv('Doench2014_V2_Featurized.csv')\n",
    "df_V2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
